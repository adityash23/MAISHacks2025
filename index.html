<!DOCTYPE html>

<html lang="en">
    <head>
        
        <title>translateASL</title>
        <link rel="icon" type="image/svg" href="assets/ASL.svg">

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width,initial-scale=1, interactive-widget=resizes-content">


        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&family=Fraunces:ital,opsz,wght@0,9..144,100..900;1,9..144,100..900&display=swap" rel="stylesheet">

        <link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:ital,opsz,wght@0,8..144,100..900;1,8..144,100..900&display=swap" rel="stylesheet">

    </head>

    <style>
     
     :root {
       --inputMode: "Speech";
       --inputPrompt: "Begin recording";

       --outputMode: "Gestures";
     }
     
     body {
       display: flex;
       flex-direction: column;
       justify-content: flex-start;
       align-items: center;
       height: 100vh;
       width: 100vw;
       margin: 0;
       gap: 5vh;
       overflow: hidden;
     }

     #title {
       font-family: Fraunces;
       font-weight: 100;
       font-size: 2.8rem;
       position: relative;
       padding: 0;
       margin: 0;
       margin-top: 1.9vh;
       transition: right 1.75s;
       right: 0;
       cursor: pointer;
     }

     span {
       display: inline-block;
     }

     span.upper {
       font-weight: 470;
       position: relative;
     }

     span.upper::before {
       content: attr(data-val);
       position: absolute;
       color: black;
       font-weight: 470;
       left: 0;
       transition: left 1.75s;
     }
     span:nth-of-type(3) {
       color: transparent;
     }
     span:nth-of-type(5) {
       color: transparent;
     }
     span:nth-of-type(6) {
       color: transparent;
     }

     
     #title.computed {
       span {
         transition: min-width 1.75s, color 1.75s, left 1.75s;
       }
       span:nth-of-type(3) {
         min-width: var(--bigA);
       }
       span:nth-of-type(5) {
         min-width: var(--bigS);
       }
       span:nth-of-type(6) {
         min-width: var(--bigL);
       }

     }

     #title.magic {
       right: calc(0.5 * (var(--bigA) + var(--bigS) + var(--bigL)));
     }

     #title.magic span:nth-of-type(3) {
       min-width: var(--smallA);
       color: black;
     }

     #title.magic span:nth-of-type(3)::before {
       left: var(--aForward);
     }

     #title.magic span:nth-of-type(5) {
       min-width: var(--smallS);
       color: black;
     }

     #title.magic span:nth-of-type(5)::before {
       left: var(--sForward);
     }

     #title.magic span:nth-of-type(6) {
       min-width: var(--smallL);
       color: black;
     }

     #title.magic span:nth-of-type(6)::before {
       left: var(--lForward);
     }


     #input::before, #output::before {
       position: absolute;
       margin: 0;
       font-family: Fraunces;
       transition: transform 0.4s;
       z-index: -2;
     }

     /* stream headers */
     #input::before, #output::before {
       top: calc(-1.5 * clamp(1.5rem, 5vmin, 2.1rem));
       font-size: clamp(1.5rem, 5vmin, 2.1rem);
       font-weight: 425;
       width: min-content;
     }

     #input::before {content: var(--inputMode); }
     #output::before {content: var(--outputMode);}
     
     #input.swapout::before, #input.swapout::after {
       transform: translateY(4.5rem) rotate(-20deg);
     }

     #output.swapout::before, #output.swapout::after  {
       transform: translateY(4.5rem) rotate(20deg);
     }

     #wrap-convert {
       display: flex;
       flex-direction: row;
       justify-content: center;
       width: 90vw;
       gap: 2vw;
       align-items: center;
       align-content: center;
       flex-grow: 0.6;
       flex-wrap: wrap;
       margin-top: 3vh;
     }

     #swap {
       width: 40px;
       opacity: 0.9;
       cursor: pointer;
       background-image: url("assets/SWAP.svg");
       background-size: 100%;
       background-repeat: no-repeat;
       height: 53.5px;
       padding: 0;
       background-color: transparent;
       border: 0;
       transition: filter 0.15s, scale 0.1s;

       &:hover {
         filter: drop-shadow(2px 2px 1px #bbb);
       }
     }

     #input, #output {
       height: 50vh;
       max-height: 60vh;
       max-width: 40vw;
       flex: 1 1 0px;
       border: 1px solid #C3C3C3;
       box-shadow: 0 0 3px #f4f4f4, 0 0 2px #f0f0f0, 0 0 1px #e5e5e5;

       padding: 0;

       box-sizing: border-box;
       border-radius: 10px;
       font-family: Fraunces;
       display: flex;
       flex-direction: column;
       position: relative;
       align-items: center;
     }

     #input {
       background-color: #FBFBFB;

     }
     #output {
       background-color: #EEE;
     }

     

     
     #recordprompt {
       position: absolute;
       top: 50%;
       transform: translateY(-50%);
       display: flex;
       flex-direction: column;
       align-items: center;
       gap: 0.5vh;

       z-index: 2;

       transition: top 0.38s ease-out;
       
       &::after {
         content: var(--inputPrompt);
         display: block;
         margin: 0;
         white-space: nowrap;

         font-family: Fraunces;
       }
     }

     .prompt::after {
       font-weight: 300;
       font-size: 1rem;
       margin: 0;
       color: #888;
       opacity: 1;
       transition: opacity 0.2s ease-out;
     }

     #record {
       padding: 0;
       border: 0;
       background: transparent;
       cursor: pointer;
       position: relative;
     }
     
     .gesturesspeech #record {
       width: 50px;
       height: 50px;
       border: 3px solid black;
       border-radius: 50%;
       
       transition: scale 0.1s, top 0.4s, opacity 0.4s;

       display: flex;
       justify-content: center;
       align-items: center;

       &:hover::before, &:active::before {
         width: 65%;
         height: 65%;

       }
       &::before {
         background: hsl(3, 45%, 42%);
         content: "";
         width: 54%;
         height: 54%;
         display: block;
         border-radius: 50%;

         position: relative;

         transition: scale 0.1s, width 0.1s ease-out, height 0.1s ease-out;
       }
     }

     .speechgestures #record {
       background: url("assets/MIC.svg");
       background-size: 100%;
       width: 31.5px;
       height: 50px;
       
       transition: opacity 0.4s, filter 0.1s;

       &::after {
         position: absolute;
         content: "";
         top: 0;
         left: 0;
         right: 0;
         z-index: -1;
         height: 100%;
         width: 100%;
         transform: scale(0) translateZ(0);
         filter: blur(15px);
         background: linear-gradient(
           to left,
           #001F54,  
           #023E8A,  
           #3A0CA3,  
           #7209B7,  
           #B5179E,  
           #7209B7,  
           #3A0CA3,  
           #023E8A,  
           #001F54    
         );
         transition: transform 0.15s ease-out;

         background-size: 200% 200%;
         animation: animateGlow 2s linear infinite;
       }
       
       &:hover::after {
         transform: scale(0.55) translateZ(0);
       }
     }

     
     .speechgestures .recording #record {
       &::after {
         transform: scale(0.8) translateZ(0);
       }
     }
     
     @keyframes animateGlow {
       0% {
         background-position: 0% 50%;
       }
       100% {
         background-position: 200% 50%;
       }
     }


     @keyframes waiting {
       0% {scale: 1;}
       50% {scale: 0.85;}
       100% {scale: 1;}
     }
     
     #input.loading {
       #recordprompt {
         &::after { transition: opacity 0.1s; opacity: 0; }
         #record {
           animation: waiting 0.9s infinite;
         }
       }

       &.loadingmore #recordprompt::after {
         opacity: 1;
       }
     }
     
     .gesturesspeech #input.recording #recordprompt {
       position: absolute;
       flex-direction: row;
       top: calc(clamp(1rem, 2vh + 1vw, 1.7rem) + var(--vidHeight));
       
       #record {
         width: 33px;
         height: 33px;

         &::before {
           border-radius: 1.5px;
         }
       }

       &::after {
         opacity: 0;
         animation: bringStopPrompt 0.2s 0.26s forwards;
       }
     }
     
     @keyframes bringStopPrompt {
       from {opacity: 0;}
       to {opacity: 1;}
     }

     #hands, #waveform {
       position: absolute;
       top: 50%;
       transform: translateY(-50%);
       display: none;
       transition: opacity 0.4s;
     }

     .gesturesspeech #waveform {
       display: block;
       
       width: 75px;
       opacity: 0.3;
     }

     .speechgestures #hands {
       display: block;
       
       width: 90px;
       opacity: 0.3;
     }

     .recording #waveform, .viewing #waveform,
     .recording #hands, .viewing #hands {
       opacity: 0;
     }
     

     .swapout {
       #hands, #waveform, #record, #signbox, #text, #playprompt {
         opacity: 0 !important;
       }
     }

     
     #playprompt {
       margin-top: auto;
       display: flex;
       flex-direction: column;
       align-items: center;
       gap: 1vh;

       display: none;
       transition: opacity 0.4s;

       #play {
         padding: 0;
         border: 0;
         background: url("assets/VOLUME.svg");
         background-size: 100%;

         cursor: pointer;
         opacity: 0.8;
         width: 50px;
         height: 50px;

         transition: transform 0.1s;

       }
     }

     .gesturesspeech .viewing #playprompt, .gesturesspeech .recordingcontent #playprompt {
       display: block;
     }
     

     
     #livevid {
       display: none;
       filter: grayscale(0); /* prevents black line */
     }

     
     .gesturesspeech #input.recording, .gesturesspeech #input.viewing {
       transition: max-height 0.25s ease-out, max-width 0.25s ease-out;
       max-height: var(--vidHeight);
       max-width: var(--vidWidth);
     }

     .gesturesspeech #input.recording {
       #livevid {
         display: block;
         width: 100%;
         height: 100%;
         opacity: 1;

         border-radius: 10px;
         transition: opacity 0.3s;
         &.terminate {
           opacity: 0;
         }
       }
     }

     #text { display: none;}

     .gesturesspeech .recording #text, .gesturesspeech .viewing #text {
       display: block;
       font-weight: 500;
       font-size: 1.5rem;
       text-align: center;
       margin-bottom: auto;
       word-break: break-all;
       transition: opacity 0.4s;
     }

     #signbox { display: none; }

     .speechgestures .recording #signbox, .speechgestures .viewing #signbox {
       display: flex;
       flex-direction: row;
       flex-wrap: wrap;
       height: 100%;
       gap: 5px;
       scrollbar-width: none;

       overflow: scroll;
       align-items: center;
       align-content: flex-start;
       transition: opacity 0.4s;

       span {
         position: relative;
         display: flex;
         justify-content: center;

         margin-bottom: 1.3rem;
         
         scale: 1;
         transition: scale 0.2s;

         @starting-style {
           scale: 0;
         }
         
         img {
           width: 40px;
           height: 40px;
           
         }
         &::before {
           content: attr(data-c);
           position: absolute;
           font-size: 1.2rem;
           font-weight: 520;
           bottom: -1.3rem;
           
         }
       }
     }




     .nudged, .nudged::after, .nudged::before {
       scale: 0.95;
     }
    </style>

    <body>

        <h1 id="title">

            <span>t</span><span>r</span><span class="upper" data-val="A">A</span><span>n</span><span class="upper" data-val="S">S</span><span class="upper" data-val="L">L</span><span>a</span><span>t</span><span>e</span>

        </h1>

        
        

        <div id="wrap-convert" class="speechgestures">
            
            
            <div id="input">

                <div id="recordprompt" class="prompt">
                    <button id="record"></button>
                </div>

                <video id="livevid" autoplay="true"> </video>

            </div>
            
            <button id="swap"></button>

            
            <div id="output">
                
                <img id="waveform" src="assets/WAVEFORM.svg">
                <img id="hands" src="assets/ASL.svg">

                <div id="playprompt" class="prompt">
                    <button id="play"></button>
                </div>

                <div id="signbox"></div>

                <div id="text"></div>

                
                
            </div>
        </div>
    </body>

    <script>
     const TITLE = document.getElementById("title");
     const SPANS = TITLE.querySelectorAll("span");

     TITLE.onclick = () => {
       TITLE.classList.toggle("magic");
     };
     
     let nMap = new Map();
     let gapMap = new Map();
     let bigGapMap = new Map();

     let aForward = 0;
     let sForward = 0;
     let lForward = 0;

     let sArray = Array.from(SPANS);

     [sArray[2], sArray[4], sArray[5]].forEach( s => {
       document.documentElement.style.setProperty(`--big${s.innerText}`,  `${s.getBoundingClientRect().width}px`);
       bigGapMap.set(s.innerText, s.getBoundingClientRect().width);
     });

     setTimeout( () => {
       for (let i=2; i < sArray.length; i++) {
         s = sArray[i];
         nMap.set(s.innerText, s);
         let oldWidth = s.getBoundingClientRect().width;
         
         
         s.innerText = s.innerText.toLowerCase();
         s.style.fontWeight = 100;

         newWidth = s.getBoundingClientRect().width;

         s.style.minWidth = oldWidth;

         gapMap.set(s, newWidth);
         aForward += newWidth;
         if (i >= 4) sForward += newWidth;
         if (i >= 5) lForward += newWidth;
       }

       [sArray[2], sArray[4], sArray[5]].forEach( s => { document.documentElement.style.setProperty(`--small${s.innerText.toUpperCase()}`, `${gapMap.get(s)}px`);
       });

       TITLE.classList.add("computed");



       sForward += bigGapMap.get("A");
       lForward += bigGapMap.get("A");
       lForward += bigGapMap.get("S");

       
       
       document.documentElement.style.setProperty("--aForward", `${aForward}px`);
       document.documentElement.style.setProperty("--sForward", `${sForward}px`);
       document.documentElement.style.setProperty("--lForward", `${lForward}px`);


       setTimeout( () => {

         TITLE.classList.add("magic");
       }, 20);

     }, 1500);
    </script>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>

    <script>
     const URL = "https://teachablemachine.withgoogle.com/models/D5a-ucXZd/";

     let model;
     async function init() {
       const modelURL = URL + "model.json";
       const metadataURL = URL + "metadata.json";


       model = await tmImage.load(modelURL, metadataURL);
       maxPredictions = model.getTotalClasses();

     }

     init();
     const RECORD = document.getElementById("record");
     const SWAP = document.getElementById("swap");

     const WRAP = document.getElementById("wrap-convert");
     const INPUT = document.getElementById("input");
     const OUTPUT = document.getElementById("output");
     const CANRECOGNIZE = 'SpeechRecognition' in window || 'webkitSpeechRecognition' in window;
     
     

     const VIDEO = document.getElementById("livevid");

     const TEXT = document.getElementById("text");

     const PLAY = document.getElementById("play");
     const SIGNBOX = document.getElementById("signbox");
     
     let ratio = 1;

     async function predictFrame(img) {
       const prediction = await model.predict(img);

       
       let c = prediction.reduce( (a,b) => {
         return (a.probability > b.probability) ? a : b
       }).className;
       

       console.log(c);
       addLetter(c);

       return;

     }
     let allow = true;
     let lastChar = '';
     let repeatCount = 0;
     let repeatThreshold = 12;

     function addLetter(c) {
       if (c === lastChar) {
         repeatCount++;
       } else {
         lastChar = c;
         repeatCount = 1;
         allow = true;
       }

       if (repeatCount < repeatThreshold || !allow) {
         return;
       }

       if (c === "space") {
         token = " ";
       } else if ("ABCDEFGHIJKLMNOPQRSTUVWXYZ".includes(c)) {
         token = (text.innerText.length > 0) ? c.toLowerCase() : c;
       }
       TEXT.innerText += token;

       OUTPUT.classList.add("recordingcontent");
       allow = false;
     }
     
     function speak(text) {
       const SYNTH = window.speechSynthesis;
       const VOICES = SYNTH.getVoices();

       const utterance = new SpeechSynthesisUtterance(text);
       
       utterance.voice = VOICES[1];

       utterance.rate = 1; 

       utterance.pitch = 1;
       SYNTH.speak(utterance);    
     }

     PLAY.onclick = () => {
       speak(text.innerText);
     };

     function swapTitles() {

       let root = window.getComputedStyle(document.documentElement);

       [newInputTitle, newOutputTitle] = [ root.getPropertyValue("--outputMode"), root.getPropertyValue("--inputMode")];
       
       if (WRAP.classList.contains("gesturesspeech")) {
         WRAP.classList.remove("gesturesspeech");
         WRAP.classList.add("speechgestures");
       } else {
         WRAP.classList.remove("speechgestures");
         WRAP.classList.add("gesturesspeech");
       }

       document.documentElement.style.setProperty("--inputMode", newInputTitle);
       document.documentElement.style.setProperty("--outputMode", newOutputTitle);
       

       INPUT.classList.remove("swapout");
       OUTPUT.classList.remove("swapout");

       OUTPUT.classList.remove("viewing");


       INPUT.removeEventListener("transitionend", swapTitles);
     }
     
     SWAP.onclick = () => {
       if (INPUT.classList.contains("recording") && WRAP.classList.contains("gesturesspeech")) {
         stopVideoRecording();
       } else if (INPUT.classList.contains("recording")) {
         stopAudioRecording();
       }
       

       INPUT.classList.add("swapout");
       OUTPUT.classList.add("swapout");

       INPUT.addEventListener("transitionend", swapTitles);

     }
     let interval;

     
     let preview = document.createElement("canvas");
     var context = preview.getContext("2d")
     
     function captureFrames(vid) {
       interval = setInterval(function () {
         context.drawImage(VIDEO, 0, 0, VIDEO.clientWidth, VIDEO.clientHeight);
         
         predictFrame(preview);
       }, 100);
     }


     function stopVideoRecording() {
       clearInterval(interval);
       stream.getTracks().forEach((track) => {
         track.stop();
       });
       VIDEO.classList.add("terminate");
       VIDEO.ontransitionend = () => {
         VIDEO.ontransitionend = "";

         INPUT.classList.remove("recording");
         OUTPUT.classList.remove("recording");
         OUTPUT.classList.remove("recordingcontent");

         VIDEO.classList.remove("terminate");
         document.documentElement.style.setProperty("--inputPrompt", "'Begin recording'");

         INPUT.classList.add("viewing");
         OUTPUT.classList.add("viewing");
         document.documentElement.style.setProperty("--vidWidth", `40vw`);
         document.documentElement.style.setProperty("--vidHeight", `60vh`);
         ratio = 1;
       };
       window.onresize = "";
       
     }


     function translateToGestures(str) {
       let chars = str.split("");

       let els = chars.map( c => {
         let sp = document.createElement("span");
         let img = new Image();
         if (!"ABCDEFGHIJKLMNOPQRSTUVWXYZ".includes(c.toUpperCase())) {
           img.src ='assets/SPACE.svg';
         } else {
           img.src = `assets/Sign_language_${c.toUpperCase()}.svg`;
         }

         sp.setAttribute("data-c", `${c}`);
         sp.appendChild(img);

         return sp;
       });

       SIGNBOX.append(...els);
       
     }
     
     function stopAudioRecording() {
       recognition.stop();
       INPUT.classList.remove("recording");
       OUTPUT.classList.remove("recording");

       document.documentElement.style.setProperty("--inputPrompt", "'Begin recording'");
     }

     let stream;
     let recognition = new webkitSpeechRecognition() || new SpeechRecognition();

     recognition.lang = "en-GB";

     recognition.interimResults = true;
     recognition.continuous = true;

     RECORD.onclick = () => {
       OUTPUT.classList.remove("viewing");

       if (INPUT.classList.contains("recording") && WRAP.classList.contains("gesturesspeech")) {
         clearInterval(interval);
         stopVideoRecording();
         return;
       } else if (INPUT.classList.contains("recording") && !OUTPUT.classList.contains("viewing")) {
         OUTPUT.classList.add("viewing");
         stopAudioRecording();
         return;
       } else if (OUTPUT.classList.contains("viewing")) {
         OUTPUT.classList.remove("viewing");
       }


       if (WRAP.classList.contains("speechgestures")) {
         recognition.start();

         SIGNBOX.innerHTML ="";
         INPUT.classList.add("recording");
         OUTPUT.classList.add("recording");

         recognition.onresult = event => {
           const result = event.results[event.results.length - 1][0].transcript;
           let text = Array.from(event.results).map( x => x[0].transcript).join("");

           if (text.length > SIGNBOX.children.length) {
             translateToGestures(text.substring(SIGNBOX.children.length));

           }
           
         };
         recognition.onend = () => {
           if (INPUT.classList.contains("recording")) {
             recognition.start();
           }
         };

         recognition.onerror = event => {
           console.error('Speech recognition error:', event.error);
         };

         recognition.onnomatch = () => {
           console.log('No speech was recognized.');
         };

         INPUT.classList.add("loading");

         function wrapup() {
           document.documentElement.style.setProperty("--inputPrompt", "'Stop recording'");
           INPUT.classList.remove("loading");
           RECORD.parentNode.removeEventListener("transitionend", wrapup);
         }
         RECORD.parentNode.addEventListener("transitionend", wrapup);
         
         

         
       } else {

         INPUT.classList.add("loading");
         function handle() {
           document.documentElement.style.setProperty("--inputPrompt", "'Loading stream...'");
           INPUT.classList.add("loadingmore");
           INPUT.removeEventListener("transitionend", handle);
         }

         INPUT.addEventListener("transitionend", handle);
         
         navigator.mediaDevices
                  .getUserMedia({
                    audio: false,
                    video: true,
                  })
                  .then((s) => {
                    stream = s;
                    const videoTracks = stream.getVideoTracks();

                    ratio = stream.getVideoTracks()[0].getSettings().aspectRatio;
                    resizeInput();

                    
                    
                    VIDEO.srcObject = stream;
                    document.documentElement.style.setProperty("--inputPrompt", "'Stop recording'");
                    TEXT.innerText = "";
                    
                    INPUT.classList.add("recording");
                    OUTPUT.classList.add("recording");

                    INPUT.classList.remove("loading");
                    INPUT.classList.remove("loadingmore");

                    window.onresize = resizeCallback;

                    setTimeout( () => {
                      captureFrames();
                    }, 300);
                  })
                  .catch((error) => {
                    if (error.name === "NotAllowedError") {
                      console.error(
                        "You need to grant this page permission to access your camera and microphone.",
                      );
                    } else {
                      console.error(`getUserMedia error: ${error.name}`, error);
                    }
                  });
       }
     }


     function resizeInput() {
       let cardWidth = OUTPUT.clientWidth;
       let cardHeight = OUTPUT.clientHeight;


       let videoWidth, videoHeight;

       videoWidth = cardWidth;
       videoHeight = cardWidth / ratio;

       if (videoHeight > cardHeight) {
         videoHeight = cardHeight;
         videoWidth = cardHeight * ratio;
       }

       preview.width = videoWidth;
       preview.height = videoHeight;

       document.documentElement.style.setProperty("--vidWidth", `${videoWidth}px`);
       document.documentElement.style.setProperty("--vidHeight", `${videoHeight}px`);
     }


     function resizeCallback() {
       INPUT.style.transition = "none";
       RECORD.parentNode.style.transition = "none";
       resizeInput();
       INPUT.style.transition = "";
       RECORD.parentNode.style.transition = "";
     }
     
     document.querySelectorAll("button").forEach(b => {
       b.addEventListener("pointerdown", (event) => {
         event.target.classList.add("nudged");
         event.target.addEventListener("pointerup", (event) => {
           event.target.classList.remove("nudged");
         });
         
       });
     });

     document.addEventListener("pointerup", () => {
       document.querySelectorAll(".nudged").forEach( n => {
         n.classList.remove("nudged");
       });
     });
    </script>
</html>

