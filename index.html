<!DOCTYPE html>

<html lang="en">
    <head>
        
        <title>translateASL</title>
        <link rel="icon" type="image/svg" href="assets/ASL.svg">

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width,initial-scale=1, interactive-widget=resizes-content">


        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

        <link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&family=Fraunces:ital,opsz,wght@0,9..144,100..900;1,9..144,100..900&display=swap" rel="stylesheet">

        <link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:ital,opsz,wght@0,8..144,100..900;1,8..144,100..900&display=swap" rel="stylesheet">

    </head>

    <style>
     
     :root {
       --inputMode: "Speech";
       --inputPrompt: "Begin recording";

       --outputMode: "Gestures";

       --opacityTrigger: 0.3;
     }
     
     * {
       -webkit-tap-highlight-color: transparent;
       -webkit-user-select: none;
       user-select: none;
     }
     
     body {
       display: flex;
       flex-direction: column;
       justify-content: flex-start;
       align-items: center;
       height: 100vh;
       width: 100vw;
       margin: 0;
       gap: 5vh;
       overflow: hidden;
     }

     #title {
       font-family: Fraunces;
       font-weight: 100;
       font-size: 2.8rem;
       position: relative;
       padding: 0;
       margin: 0;
       margin-top: 1.9vh;
       transition: right 1.75s;
       right: 0;
       cursor: pointer;
       
       span {
         display: inline-block;
       }

       span.upper {
         font-weight: 470;
         position: relative;
       }

       span.upper::before {
         content: attr(data-val);
         position: absolute;
         color: black;
         font-weight: 470;
         left: 0;
         transition: left 1.75s;
       }
       span:nth-of-type(3) {
         color: transparent;
       }
       span:nth-of-type(5) {
         color: transparent;
       }
       span:nth-of-type(6) {
         color: transparent;
       }

       
       &.computed {
         span {
           transition: min-width 1.75s, color 1.75s, left 1.75s;
         }
         span:nth-of-type(3) {
           min-width: var(--bigA);
         }
         span:nth-of-type(5) {
           min-width: var(--bigS);
         }
         span:nth-of-type(6) {
           min-width: var(--bigL);
         }

       }
     }

     #title.magic {
       right: calc(0.5 * (var(--bigA) + var(--bigS) + var(--bigL)));
     }

     #title.magic span:nth-of-type(3) {
       min-width: var(--smallA);
       color: black;
     }

     #title.magic span:nth-of-type(3)::before {
       left: var(--aForward);
     }

     #title.magic span:nth-of-type(5) {
       min-width: var(--smallS);
       color: black;
     }

     #title.magic span:nth-of-type(5)::before {
       left: var(--sForward);
     }

     #title.magic span:nth-of-type(6) {
       min-width: var(--smallL);
       color: black;
     }

     #title.magic span:nth-of-type(6)::before {
       left: var(--lForward);
     }


     #input::before, #output::before {
       position: absolute;
       margin: 0;
       font-family: Fraunces;
       transition: transform 0.4s;
       z-index: -2;
     }

     /* stream headers */
     #input::before, #output::before {
       top: calc(-1.5 * clamp(1.5rem, 5vmin, 2.1rem));
       font-size: clamp(1.5rem, 5vmin, 2.1rem);
       font-weight: 425;
       width: min-content;
     }

     #input::before {content: var(--inputMode); }
     #output::before {content: var(--outputMode);}
     
     #input.swapout::before {
       transform: translateY(4.5rem) rotate(-20deg);
     }

     #output.swapout::before {
       transform: translateY(4.5rem) rotate(20deg);
     }

     #wrap-convert {
       display: flex;
       flex-direction: row;
       justify-content: center;
       width: 90vw;
       gap: 2vw;
       align-items: center;
       align-content: center;
       flex-grow: 0.6;
       flex-wrap: wrap;
       margin-top: 3vh;
     }

     #swap {
       width: 40px;
       opacity: 0.9;
       cursor: pointer;
       background-image: url("assets/SWAP.svg");
       background-size: 100%;
       background-repeat: no-repeat;
       height: 53.5px;
       padding: 0;
       background-color: transparent;
       border: 0;
       transition: filter 0.15s, scale 0.1s;

       &:hover {
         filter: drop-shadow(2px 2px 1px #bbb);
       }
     }

     #input, #output {
       height: 50vh;
       max-height: 60vh;
       max-width: 40vw;
       flex: 1 1 0px;
       border: 1px solid #C3C3C3;
       box-shadow: 0 0 5px #f0f0f0, 0 0 3px #efefef, 0 0 1px #e0e0e0;

       padding: 0;
       justify-content: center;

       box-sizing: border-box;
       border-radius: 10px;
       font-family: Fraunces;
       display: flex;
       flex-direction: column;
       position: relative;
       align-items: center;
     }

     #input {
       background-color: #FBFBFB;
       transition: max-height 0.25s ease-out, max-width 0.25s ease-out;
     }
     #output {
       background-color: #EEE;
       padding: 1vmin;
       padding-top: 2.2vmin;
     }

     

     
     #recordprompt {
       position: absolute;
       top: 50%;
       transform: translateY(-50%);
       display: flex;
       flex-direction: column;
       align-items: center;
       gap: 0.65vh;

       z-index: 2;

       transition: top 0.38s ease-out;
       
       &::after {
         content: var(--inputPrompt);
         display: block;
         margin: 0;
         white-space: nowrap;

         font-family: Fraunces;
       }
     }

     .prompt::after, #waiting {
       font-weight: 300;
       font-size: 1rem;
       margin: 0;
       color: #888;
       opacity: 1;
       transition: opacity 0.2s ease-out;
     }

     #record {
       padding: 0;
       border: 0;
       background: transparent;
       cursor: pointer;
       position: relative;
     }
     
     .gesturesspeech #record {
       width: 50px;
       height: 50px;
       border: 3px solid black;
       border-radius: 50%;
       
       transition: scale 0.1s, top 0.4s, opacity 0.4s, filter 0.2s;

       display: flex;
       justify-content: center;
       align-items: center;

       &:hover {
         filter: drop-shadow(2px 2px 1px #bbb);
       }
       &::before {
         background: hsl(3, 45%, 42%);
         content: "";
         width: 54%;
         height: 54%;
         display: block;
         border-radius: 50%;

         position: relative;

         transition: scale 0.1s, width 0.1s ease-out, height 0.1s ease-out;
       }
     }

     .speechgestures #record {
       background: url("assets/MIC.svg");
       background-size: 100%;
       width: 31.5px;
       height: 50px;

       display: flex;
       justify-content: center;
       align-items: center;
       transition: opacity 0.4s, filter 0.1s;
       &::after {
         position: relative;
         content: "";
         top: 0;
         left: 0;
         right: 0;
         z-index: -1;
         height: 100%;
         width: 100%;
         transform: scale(0) translateZ(0);
         filter: blur(15px);
         background: linear-gradient(
           to left,
           #001F54,  
           #023E8A,  
           #3A0CA3,  
           #7209B7,  
           #B5179E,  
           #7209B7,  
           #3A0CA3,  
           #023E8A,  
           #001F54    
         );
         transition: transform 0.3s ease-out;

         background-size: 200% 200%;
       }
       
       #input:not(.recording) &:hover {
         filter: drop-shadow(2px 2px 1px #bbb);
       }
     }

     
     .speechgestures .recording #record {
       &::after {
         transform: scale(0.75) translateZ(0);
         animation: animateGlow 2s linear infinite;
       }
     }
     
     @keyframes animateGlow {
       0% {
         background-position: 0% 50%;
       }
       100% {
         background-position: 200% 50%;
       }
     }


     @keyframes waiting {
       0% {scale: 1;}
       50% {scale: 0.85;}
       100% {scale: 1;}
     }
     
     #input.loading {
       #recordprompt {
         &::after { transition: opacity 0.1s; opacity: 0; }
         
       }

       &.loadingmore #recordprompt::after {
         opacity: 1;
       }
     }

     .gesturesspeech .loading #recordprompt #record {
       animation: waiting 0.9s infinite;
     }
     
     .gesturesspeech #input.recording #recordprompt {
       position: absolute;
       flex-direction: row;
       top: calc(clamp(1rem, 2vh + 1vw, 1.7rem) + var(--vidHeight));
       
       #record {
         width: 33px;
         height: 33px;

         &::before {
           border-radius: 1.5px;
         }
       }

       &::after {
         opacity: 0;
         animation: bringStopPrompt 0.2s 0.26s forwards;
       }
     }
     
     @keyframes bringStopPrompt {
       from {opacity: 0;}
       to {opacity: 1;}
     }

     #hands, #waveform {
       position: absolute;
       top: 50%;
       transform: translateY(-50%);
       display: none;
       transition: opacity 0.4s;


       @starting-style {
         opacity: var(--opacityTrigger) !important;
       }
     }

     .gesturesspeech #waveform {
       display: block;
       
       width: 75px;
       opacity: 0.3;
     }

     .speechgestures #hands {
       display: block;
       
       width: 90px;
       opacity: 0.3;
     }

     .loading #waveform, .recording #waveform, .viewing #waveform,
     .loading #hands, .recording #hands, .viewing #hands {
       opacity: 0;
     }
     

     .swapout {
       #hands, #waveform, #record, #signbox, #text, #playprompt {
         opacity: 0 !important;
       }
     }

     
     #playprompt {
       margin-top: auto;
       display: flex;
       flex-direction: column;
       align-items: center;
       gap: 1vh;

       display: none;
       transition: opacity 0.4s;

       #play {
         padding: 0;
         border: 0;
         background: url("assets/VOLUME.svg");
         background-size: 100%;

         cursor: pointer;
         opacity: 0.8;
         width: 50px;
         height: 50px;

         transition: transform 0.1s;

       }
     }

     .gesturesspeech .viewing #playprompt, .gesturesspeech .recordingcontent #playprompt {
       display: block;
     }

     .gesturespeech .recordingcontent #playprompt {
       animation: forceFade 0.4s forwards;
     }

     @keyframes forceFade {
       from {opacity: 0} to {opacity: 1}
     }
     
     
     #livevid {
       display: none;
       filter: grayscale(0); /* prevents black line */
     }

     
     .gesturesspeech #input.recording, .gesturesspeech #input.viewing {
       max-height: var(--vidHeight);
       max-width: var(--vidWidth);
     }

     .gesturesspeech #input.recording {
       #livevid {
         display: block;
         width: 100%;
         height: 100%;
         opacity: 1;

         border-radius: 10px;
         transition: opacity 0.3s;
         &.terminate {
           opacity: 0;
         }
       }
     }

     #text { display: none;}

     .gesturesspeech .recording #text, .gesturesspeech .viewing #text {
       display: block;
       font-weight: 500;
       font-size: 1.5rem;
       text-align: center;
       margin-bottom: auto;
       word-break: break-all;
       transition: opacity 0.4s;
     }

     .gesturesspeech .recording #text {
       animation: forceFade 0.4s forwards;
     }

     #signbox { display: none; }

     .speechgestures .recording #signbox, .speechgestures .viewing #signbox {
       display: flex;
       flex-direction: row;
       flex-wrap: wrap;
       height: 100%;
       gap: 5px;
       scrollbar-width: none;

       overflow: scroll;
       align-items: center;
       align-content: flex-start;
       justify-content: center;
       transition: opacity 0.4s;

       span {
         position: relative;
         display: flex;
         justify-content: center;

         margin-bottom: 1.3rem;
         
         scale: 1;
         transition: scale 0.2s;

         @starting-style {
           scale: 0;
         }
         
         img {
           width: 40px;
           height: 40px;
           
         }
         &::before {
           content: attr(data-c);
           position: absolute;
           font-size: 1.2rem;
           font-weight: 520;
           bottom: -1.3rem;
           
         }
       }
     }

     .loading { .ellipsis, .ellipsis::before, .ellipsis::after {
       opacity: 1;
     }}

     .ellipsis {
       position: absolute;
       opacity: 0;
       width: 12px;
       height: 12px;
       border-radius: 10px;
       background-color: var(--dotColor);
       animation: dot-flashing 0.8s infinite linear alternate;
       animation-delay: 0.4s;
       --dotColor: hsl(200, 25%, 80%);
       transition: opacity 0.5s;
       display: flex;
       justify-content: center;
     }
     .ellipsis::before {
       left: -15px;
       width: 12px;
       height: 12px;
       border-radius: 10px;
       background-color: var(--dotColor);
       animation: dot-flashing .8s infinite linear alternate;
       animation-delay: 0s;
     }

     .ellipsis::before, .ellipsis::after {
       content: "";
       display: inline-block;
       position: absolute;
       top: 0;
     }
     .ellipsis::after {
       left: 15px;
       width: 12px;
       height: 12px;
       border-radius: 10px;
       background-color: var(--dotColor);
       animation: dot-flashing 0.8s infinite linear alternate;
       animation-delay: 0.8s;
     }

     #waiting {
       position: absolute;
       top: 16px;
       font-style: italic;
       white-space: nowrap;
     }

     #warning {
       margin-top: -12vh;
       font-family: Fraunces;
       font-weight: 200;
       font-style: italic;
       position: relative;
       font-size: 1.2rem;
       bottom: 1vh;
       opacity: 0;
       text-align: center;
       transition: opacity 0.4s;
     }

     .gesturesspeech:not(:has(.recording, .viewing)) + #warning {
       opacity: 1;
     }

     
     
     @keyframes dot-flashing {
       0% {
         background-color: var(--dotColor);
       }
       50%, 100% {
         background-color: hsl(222,10%, 40%);
         
       }
     }

     
     .nudged, .nudged::before, .nudged::after {
       scale: 0.95;
     }


    </style>

    <body>

        <h1 id="title">

            <span>t</span><span>r</span><span class="upper" data-val="A">A</span><span>n</span><span class="upper" data-val="S">S</span><span class="upper" data-val="L">L</span><span>a</span><span>t</span><span>e</span>

        </h1>

        
        

        <div id="wrap-convert" class="speechgestures">
            
            
            <div id="input">

                <div id="recordprompt" class="prompt">
                    <button id="record"></button>
                </div>

                <video id="livevid" autoplay="true"> </video>

            </div>
            
            <button id="swap"></button>

            
            <div id="output">
                
                <img id="waveform" src="assets/WAVEFORM.svg">
                <img id="hands" src="assets/ASL.svg">

                <div id="playprompt" class="prompt">
                    <button id="play"></button>
                </div>

                <div id="signbox"></div>

                <div id="text"></div>

                <div class="ellipsis"> <span id="waiting">Waiting for input</span> </div>
                
                
            </div>
        </div>

        <p id="warning"> Warning: gesture recognition is currently very low accuracy. </p>
    </body>

    <script>
     if (!('SpeechRecognition' in window || 'webkitSpeechRecognition' in window)) {
       document.body.innerHTML = "<h1> Your browser (probably Firefox....) does not yet support an API required for this site.  <br> ☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️☹️ </h1>";
     }
    </script>
    
    <script>
     const TITLE = document.getElementById("title");
     const SPANS = TITLE.querySelectorAll("span");

     TITLE.onclick = () => {
       TITLE.classList.toggle("magic");
     };
     
     let nMap = new Map();
     let gapMap = new Map();
     let bigGapMap = new Map();

     let aForward = 0;
     let sForward = 0;
     let lForward = 0;

     let sArray = Array.from(SPANS);

     [sArray[2], sArray[4], sArray[5]].forEach( s => {
       document.documentElement.style.setProperty(`--big${s.innerText}`,  `${s.getBoundingClientRect().width}px`);
       bigGapMap.set(s.innerText, s.getBoundingClientRect().width);
     });

     setTimeout( () => {
       for (let i=2; i < sArray.length; i++) {
         s = sArray[i];
         nMap.set(s.innerText, s);
         let oldWidth = s.getBoundingClientRect().width;
         
         
         s.innerText = s.innerText.toLowerCase();
         s.style.fontWeight = 100;

         newWidth = s.getBoundingClientRect().width;

         s.style.minWidth = oldWidth;

         gapMap.set(s, newWidth);
         aForward += newWidth;
         if (i >= 4) sForward += newWidth;
         if (i >= 5) lForward += newWidth;
       }

       [sArray[2], sArray[4], sArray[5]].forEach( s => { document.documentElement.style.setProperty(`--small${s.innerText.toUpperCase()}`, `${gapMap.get(s)}px`);
       });

       TITLE.classList.add("computed");



       sForward += bigGapMap.get("A");
       lForward += bigGapMap.get("A");
       lForward += bigGapMap.get("S");

       
       
       document.documentElement.style.setProperty("--aForward", `${aForward}px`);
       document.documentElement.style.setProperty("--sForward", `${sForward}px`);
       document.documentElement.style.setProperty("--lForward", `${lForward}px`);


       setTimeout( () => {

         TITLE.classList.add("magic");
       }, 20);

     }, 650);

     // elements will fade in whenever switched to display block
     setTimeout( () => { document.documentElement.style.setProperty("--opacityTrigger", `0`);}, 100);
    </script>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>

    <script>
     const URL = "https://teachablemachine.withgoogle.com/models/D5a-ucXZd/";


     let model;
     async function init() {
       const modelURL = URL + "model.json";
       const metadataURL = URL + "metadata.json";


       model = await tmImage.load(modelURL, metadataURL);
       maxPredictions = model.getTotalClasses();

       return model;
     }
     init();

     
     const RECORD = document.getElementById("record");
     const SWAP = document.getElementById("swap");

     const WRAP = document.getElementById("wrap-convert");
     const INPUT = document.getElementById("input");
     const OUTPUT = document.getElementById("output");
     

     const VIDEO = document.getElementById("livevid");

     const TEXT = document.getElementById("text");

     const PLAY = document.getElementById("play");
     const SIGNBOX = document.getElementById("signbox");
     
     let ratio = 1;

     async function predictFrame(img) {
       const prediction = await model.predict(img);

       
       let c = prediction.reduce( (a,b) => {
         return (a.probability > b.probability) ? a : b
       }).className;
       addLetter(c);
     }


     // to prevent interpreting transitions as signs
     let allowLetter = true;
     let lastChar = '';
     let repeatCount = 0;
     let repeatThreshold = 12;

     function addLetter(c) {
       if (c === lastChar) {
         repeatCount++;
       } else {
         lastChar = c;
         repeatCount = 1;
         allowLetter = true;
       }

       if (repeatCount < repeatThreshold || !allowLetter) {
         return;
       }

       if (c === "space") {
         token = " ";
       } else if ("ABCDEFGHIJKLMNOPQRSTUVWXYZ".includes(c)) {
         token = (text.innerText.length > 0) ? c.toLowerCase() : c;
       }
       TEXT.innerText += token;

       OUTPUT.classList.remove("loading");
       OUTPUT.classList.add("recordingcontent");
       allowLetter = false;
     }
     
     function speak(text) {
       const SYNTH = window.speechSynthesis;
       const VOICES = SYNTH.getVoices();

       const utterance = new SpeechSynthesisUtterance(text);
       
       utterance.voice = VOICES[1];

       utterance.rate = 1; 

       utterance.pitch = 1;
       SYNTH.speak(utterance);    
     }

     PLAY.onclick = () => {
       speak(text.innerText);
     };

     function swapTitles() {

       let root = window.getComputedStyle(document.documentElement);

       [newInputTitle, newOutputTitle] = [ root.getPropertyValue("--outputMode"), root.getPropertyValue("--inputMode")];
       
       if (WRAP.classList.contains("gesturesspeech")) {
         WRAP.classList.remove("gesturesspeech");
         WRAP.classList.add("speechgestures");
       } else {
         WRAP.classList.remove("speechgestures");
         WRAP.classList.add("gesturesspeech");
       }

       document.documentElement.style.setProperty("--inputMode", newInputTitle);
       document.documentElement.style.setProperty("--outputMode", newOutputTitle);

       INPUT.classList.remove("swapout");
       OUTPUT.classList.remove("swapout");

       OUTPUT.classList.remove("viewing");


       INPUT.removeEventListener("transitionend", swapTitles);
     }

     function swapInputOutput() {
       if (INPUT.classList.contains("recording") && WRAP.classList.contains("gesturesspeech")) {
         stopVideoRecording();
       } else if (INPUT.classList.contains("recording")) {
         stopAudioRecording();
       }
       

       INPUT.classList.add("swapout");
       OUTPUT.classList.add("swapout");

       setTimeout(swapTitles, 400); // 400 = transition time
     }
     
     SWAP.onclick = swapInputOutput;
     
     let interval;
     
     let preview = document.createElement("canvas");
     var context = preview.getContext("2d")
     
     function captureFrames(vid) {
       interval = setInterval(function () {
         context.drawImage(VIDEO, 0, 0, VIDEO.clientWidth, VIDEO.clientHeight);
         
         predictFrame(preview);
       }, 100);
     }


     function stopVideoRecording() {
       clearInterval(interval);
       clearTimeout(launchCapture);
       stream.getTracks().forEach((track) => {
         track.stop();
       });
       VIDEO.classList.add("terminate");
       VIDEO.ontransitionend = () => {
         VIDEO.ontransitionend = "";

         INPUT.classList.remove("recording");
         OUTPUT.classList.remove("recording");
         OUTPUT.classList.remove("recordingcontent");

         VIDEO.classList.remove("terminate");
         document.documentElement.style.setProperty("--inputPrompt", "'Begin recording'");

         if (TEXT.innerText.trim().length > 0) {
           INPUT.classList.add("viewing");
           OUTPUT.classList.add("viewing");
         } else {
           OUTPUT.classList.remove("loading");
         }
         document.documentElement.style.setProperty("--vidWidth", `40vw`);
         document.documentElement.style.setProperty("--vidHeight", `60vh`);
         ratio = 1;
       };
       window.onresize = "";
     }


     function translateToGestures(str) {
       
       let chars = str.split("");

       let els = chars.map( c => {
         let sp = document.createElement("span");
         let img = new Image();
         if (!"ABCDEFGHIJKLMNOPQRSTUVWXYZ".includes(c.toUpperCase())) {
           img.src ='assets/SPACE.svg';
         } else {
           img.src = `assets/Sign_language_${c.toUpperCase()}.svg`;
         }

         sp.setAttribute("data-c", `${c}`);
         sp.appendChild(img);

         return sp;
       });
       OUTPUT.classList.remove("loading");

       SIGNBOX.append(...els);
       
     }
     
     function stopAudioRecording() {
       recognition.onend = "";
       recognition.abort();
       INPUT.classList.remove("recording");
       OUTPUT.classList.remove("recording");

       if (signbox.children.length > 0) {
         OUTPUT.classList.add("viewing");
       } else {
         OUTPUT.classList.remove("loading");
       }

       document.documentElement.style.setProperty("--inputPrompt", "'Begin recording'");
     }

     let stream;
     let recognition = new webkitSpeechRecognition() || new SpeechRecognition();

     recognition.lang = "en-GB";

     recognition.interimResults = true;
     recognition.continuous = true;

     function beginAudioRecording() {
       recognition.start();

       OUTPUT.classList.add("loading");

       SIGNBOX.innerHTML ="";
       INPUT.classList.add("recording");
       OUTPUT.classList.add("recording");

       recognition.onresult = event => {
         const result = event.results[event.results.length - 1][0].transcript;
         let text = Array.from(event.results).map( x => x[0].transcript).join("");

         if (text.length > SIGNBOX.children.length) {
           translateToGestures(text.substring(SIGNBOX.children.length));
         }
       };
       recognition.onend = () => {
         if (INPUT.classList.contains("recording")) {

           recognition.start();
         }
       };

       recognition.onerror = event => {
         console.error('Speech recognition error:', event.error);
       };

       recognition.onnomatch = () => {
         console.log('No speech was recognized.');
       };

       INPUT.classList.add("loading");

       function wrapup() {
         document.documentElement.style.setProperty("--inputPrompt", "'Stop recording'");
         INPUT.classList.remove("loading");
         RECORD.parentNode.removeEventListener("transitionend", wrapup);
       }
       RECORD.parentNode.addEventListener("transitionend", wrapup);
     }

     // careful when to start captureframes because the first predict causes stutter
     let launchCapture;

     function beginVideoRecording() {
       INPUT.classList.remove("viewing");
       INPUT.classList.add("loading");
       OUTPUT.classList.add("loading");

       TEXT.innerText = "";

       function handle() {
         document.documentElement.style.setProperty("--inputPrompt", "'Loading stream...'");
         INPUT.classList.add("loadingmore");
         INPUT.removeEventListener("transitionend", handle);
       }

       INPUT.addEventListener("transitionend", handle);

       RECORD.onclick = "";
       SWAP.onclick = "";
       
       navigator.mediaDevices
                .getUserMedia({
                  audio: false,
                  video: true,
                })
                .then((s) => {
                  stream = s;
                  const videoTracks = stream.getVideoTracks();

                  ratio = stream.getVideoTracks()[0].getSettings().aspectRatio;
                  resizeVideo();

                  VIDEO.srcObject = stream;
                  document.documentElement.style.setProperty("--inputPrompt", "'Stop recording'");
                  
                  INPUT.classList.add("recording");
                  OUTPUT.classList.add("recording");

                  INPUT.classList.remove("loading");
                  INPUT.classList.remove("loadingmore");

                  window.onresize = resizeCallback;

                  launchCapture = setTimeout(captureFrames, 300);

                  setTimeout( () => {
                    RECORD.onclick = toggleRecording;
                    SWAP.onclick = swapInputOutput;

                    
                  }, 50);
                })
                .catch((error) => {
                  if (error.name === "NotAllowedError") {
                    console.error(
                      "You need to grant this page permission to access your camera and microphone.",
                    );
                  } else {
                    console.error(`getUserMedia error: ${error.name}`, error);
                  }
                });
     }


     
     function toggleRecording() {
       OUTPUT.classList.remove("viewing");

       if (INPUT.classList.contains("recording")) {
         if (WRAP.classList.contains("gesturesspeech")) {
           stopVideoRecording();
         } else {
           stopAudioRecording();
         } 
         return;
       }
       

       if (WRAP.classList.contains("speechgestures")) {
         beginAudioRecording();
       } else if (WRAP.classList.contains("gesturesspeech")) {
         beginVideoRecording();
       }
     }

     
     RECORD.onclick = toggleRecording;

     // Ensure that video dimensions and card dimensions adapt to new  
     function resizeVideo() {
       let cardWidth = OUTPUT.clientWidth;
       let cardHeight = OUTPUT.clientHeight;

       let videoWidth, videoHeight;

       videoWidth = cardWidth;
       videoHeight = cardWidth / ratio;

       if (videoHeight > cardHeight) {
         videoHeight = cardHeight;
         videoWidth = cardHeight * ratio;
       }

       preview.width = videoWidth;
       preview.height = videoHeight;

       document.documentElement.style.setProperty("--vidWidth", `${videoWidth}px`);
       document.documentElement.style.setProperty("--vidHeight", `${videoHeight}px`);
     }


     // When adapting video to new dimensions, prevent transitions
     // (but not the first time, hence this wrapper for window.onresize)
     function resizeCallback() {
       INPUT.style.transition = "none";
       RECORD.parentNode.style.transition = "none";
       resizeVideo();
       INPUT.style.transition = "";
       RECORD.parentNode.style.transition = "";
     }


     // For tactile effect on buttons
     document.querySelectorAll("button").forEach(b => {
       b.addEventListener("pointerdown", (event) => {
         event.target.classList.add("nudged");
         event.target.addEventListener("pointerup", (event) => {
           event.target.classList.remove("nudged");
         });
       });
     });
     document.addEventListener("pointerup", () => {
       document.querySelectorAll(".nudged").forEach( n => {
         n.classList.remove("nudged");
       });
     });
    </script>
</html>

